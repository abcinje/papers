## Machine Learning

- [x] Abhishek Vijaya Kumar and Muthian Sivathanu,  
"[Quiver: An Informed Storage Cache for Deep Learning](https://www.usenix.org/system/files/fast20-kumar.pdf)," FAST, 2020.

- [x] Ruben Mayer and Hans-Arno Jacobsen,  
"[Scalable Deep Learning on Distributed Infrastructures: Challenges, Techniques, and Tools](https://dl.acm.org/doi/pdf/10.1145/3363554?download=true)," CSUR, 2020.

- [ ] Yuzhen Huang, Tatiana Jin, Yidi Wu, Zhenkun Cai, Xiao Yan, Fan Yang, Jinfeng Li, Yuying Guo, and James Cheng,  
"[FlexPS: Flexible Parallelism Control in Parameter Server Architecture](http://www.vldb.org/pvldb/vol11/p566-huang.pdf)," VLDB, 2018.

- [x] Alexander Sergeev and Mike Del Balso,  
"[Horovod: fast and easy distributed deep learning in TensorFlow](https://arxiv.org/pdf/1802.05799.pdf)," arXiv preprint, 2018.

- [x] Hao Zhang, Zeyu Zheng, Shizhen Xu, Wei Dai, Qirong Ho, Xiaodan Liang, Zhiting Hu, Jinliang Wei, Pengtao Xie, and Eric P. Xing,  
"[Poseidon: An Efficient Communication Architecture for Distributed Deep Learning on GPU Clusters](https://www.usenix.org/system/files/conference/atc17/atc17-zhang.pdf)," ATC, 2017.

- [ ] Jiawei Jiang, Bin Cui, Ce Zhang, and Lele Yu,  
"[Heterogeneity-aware Distributed Parameter Servers](https://dl.acm.org/doi/pdf/10.1145/3035918.3035933?download=true)," SIGMOD, 2017.

- [ ] Mart√≠n Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, Manjunath Kudlur, Josh Levenberg, Rajat Monga, Sherry Moore, Derek G. Murray, Benoit Steiner, Paul Tucker,
Vijay Vasudevan, Pete Warden, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng,  
"[TensorFlow: A System for Large-Scale Machine Learning](https://www.usenix.org/system/files/conference/osdi16/osdi16-abadi.pdf)," OSDI, 2016.

- [ ] Philipp Moritz, Robert Nishihara, Ion Stoica, and Michael I. Jordan,  
"[SparkNet: Training Deep Networks in Spark](https://arxiv.org/pdf/1511.06051.pdf)," ICLR, 2016.

- [ ] Henggang Cui, Hao Zhang, Gregory R. Ganger, Phillip B. Gibbons, and Eric P. Xing,  
"[GeePS: Scalable deep learning on distributed GPUs with a GPU-specialized parameter server](https://www.pdl.cmu.edu/PDL-FTP/CloudComputing/GeePS-cui-eurosys16.pdf)," EuroSys, 2016.

- [ ] Pengtao Xie, Jin Kyu Kim, Yi Zhou, Qirong Ho, Abhimanu Kumar, Yaoliang Yu, and Eric Xing,  
"[Distributed Machine Learning via Sufficient Factor Broadcasting](https://arxiv.org/pdf/1511.08486.pdf)," arXiv preprint, 2015.

- [x] Jinliang Wei, Wei Dai, Aurick Qiao, Qirong Ho, Henggang Cui, Gregory R. Ganger, Phillip B. Gibbons, Garth A. Gibson, and Eric P. Xing,  
"[Managed Communication and Consistency for Fast Data-Parallel Iterative Analytics](https://www.cs.cmu.edu/~epxing/papers/2015/Wei_etal_SoCC15.pdf)," SoCC, 2015.

- [ ] Feng Yan, Olatunji Ruwase, Yuxiong He, and Trishul Chilimbi,  
"[Performance Modeling and Scalability Optimization of Distributed Deep Learning Systems](https://dl.acm.org/doi/pdf/10.1145/2783258.2783270?download=true)," KDD, 2015.

- [ ] Trishul Chilimbi, Yutaka Suzue, Johnson Apacible, and Karthik Kalyanaraman,  
"[Project Adam: Building an Efficient and Scalable Deep Learning Training System](https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-chilimbi.pdf)," OSDI, 2014.

- [x] Jeffrey Dean, Greg S. Corrado, Rajat Monga, Kai Chen, Matthieu Devin, Quoc V. Le, Mark Z. Mao, Marc' Aurelio Ranzato, Andrew Senior, Paul Tucker, Ke Yang, and Andrew Y. Ng,  
"[Large Scale Distributed Deep Networks](https://papers.nips.cc/paper/4687-large-scale-distributed-deep-networks.pdf)," NIPS, 2012.
